---
layout: post
categories: [TIL]
---

# Today I Learned - 211115



# **How (and why) to create a good validation set**

ref: https://www.fast.ai/2017/11/13/validation-sets/

왜 cross-validation을 너무 믿으면 안 되는지 설명하고 있다. 

- 시계열 데이터의 경우는 순서가 중요하기 때문에 validation set을 train set 과 순서를 섞어 뽑으면 안되는 것. hold-out validation이 더 유용하다.

Section 2 ML Wrap-up

- Ridge / Lasso 회귀 의 차이

- - 중요하지 않은 특성을 Ridge는 그래도 남겨두지만 Lasso는 중요하지 않은 특성을 0으로 만든다.

- Stacked Ensemble 

- - 머신러닝의 성능을 높이기 위해 Kaggle 에서 많이 씀.

- Hyperparameter Tuning

- - Random, grid search 방법이 있지만, 공부를 위해서는 손으로 직접 설정하면서 해보는 게 좋다.

- Data Wrangling

- - Cheat sheet 를 적극활용!

- Boosting model

- - 머신러닝에서 가장 좋은 성능을 낼 수 있는 방법이다. 
  - 잔차를 학습(Residual fitting)하여 다음 학습에서 결과를 보정해 나간다.

- **Deep Learning**

- - transfer learning : pre-trained model 을 이용하여 추가 학습을 할 수 있다. 학습 시간을 절약하므로 효율적이다.
  - Semi-supervised learning : 레이블이 없는 데이터를 준지도학습으로 모델 성능 향상에 기여시키는 방법. 
  - Generative model (GAN 등) : 생성 모델.