## Optimization

### 중요한 용어들
- Generalization
- Under/overfitting
- cross validation
- Bias-variance tradeoff
	+ bias, variance, noise 
	+ bias 와 variance 둘다 줄이기는 힘들다. 
- Bootstrapping
	+ 랜덤 샘플링을 이용한 어떠한 테스트나 측정을 의미함.
	+ 전체적인 불확실도를 알고 싶을 때 씀.
- Bagging and boosting
	+ Bagging (Bootstrapping aggregating)
	+ Boosting
	  - 작은  여러개의 모델을 만들어 합칠 때, 이들을 sequential 하게 합쳐 강한 모델을 만든다.
	  
### Batch-size matters
- Batch size를 줄이게 되면 flat minimum으로 가는 경향이 있어 좀더 선호됨. 


### Gradient Descent - optimizers
1.  SGD  
- 단점 : step size 를 적절히 정하기 힘들다. 이를 해결하기 위해 여러가지 최적화 테크닉이 나오게 됨.
2.  Momentum   
- 이전 그래디언트 값을 활용하는 방법. 
3. Nesterov Accelerated Gradient (NAG)  
- 한 스텝 뒤에서 Lookahead gradient를 계산해서 지역 극소에 빠지는 것을 방지. 
4. Adagrad  - adaptive learning rate
- 그래디언트가 얼마나 변했는지 모니터링하고 많이 변한 파라미터는 적게. 적게 변한건 많이 업데이트하는 방식.
- 하지만 long-period 훈련에서는 학습이 점점 멈추는 현상이 생김.
5. Adadelta
- Adagrad를 발전시킨 형태. 학습이 느려지는 것을 극복하고자 accumulation window 크기를 제한함.
- Adadelta의 가장 큰 특징은 lr이 없다는 것. 그래서 많이 활용되지는 않음. 
6. RMSprop
- Geoff Hinton이 그의 강의에서 제안함. 논문도 아닌.. 
- gradient squares의 EMA와 step size를 이용 
7. Adam (Adaptive Moment Estimation)
- adaptive learning (gradient squares) + momentum 합친 형태 

### Regularization - 정규화

- 학습을 의도적으로 방해하기 - 일반화 성능을 높이기 위해서

1. Early stopping

   validation data를 이용하여 loss 가 높아지면 조기 종료시킴
   추가적인 val data 가 필요

2. Parameter Norm Penalty

3. Data Augmentation

4. Noise Robustness

   - 의도적으로 입력 데이터 혹은 뉴럴넷에 노이즈를 넣음

5. Label Smoothing
   다른 라벨의 데이터를 서로 섞어(개와 고양이 이미지를 합치는 등) 성능을 올리는 법. 데이터의 라벨의 경계를 좀더 모호하게 만들어준다. 왜? 에 대해서는 여전히 논의중.

6. Dropout

7. Batch Normalization
   이것도 논란이 있으나, 확실히 깊은 모델일 경우 성능 향상에 큰 도움이 된다고 함.

---

덜한 부분 추가 학습해서 기입할 것.

